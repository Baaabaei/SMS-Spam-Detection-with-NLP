{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":982,"sourceType":"datasetVersion","datasetId":483}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-22T20:58:40.501869Z","iopub.execute_input":"2025-11-22T20:58:40.502122Z","iopub.status.idle":"2025-11-22T20:58:42.359350Z","shell.execute_reply.started":"2025-11-22T20:58:40.502102Z","shell.execute_reply":"2025-11-22T20:58:42.358362Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/sms-spam-collection-dataset/spam.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"Preprocessing","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/sms-spam-collection-dataset/spam.csv\",encoding='latin-1')\n\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T20:58:46.303568Z","iopub.execute_input":"2025-11-22T20:58:46.303908Z","iopub.status.idle":"2025-11-22T20:58:46.358354Z","shell.execute_reply.started":"2025-11-22T20:58:46.303880Z","shell.execute_reply":"2025-11-22T20:58:46.357710Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"     v1                                                 v2 Unnamed: 2  \\\n0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n1   ham                      Ok lar... Joking wif u oni...        NaN   \n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n3   ham  U dun say so early hor... U c already then say...        NaN   \n4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n\n  Unnamed: 3 Unnamed: 4  \n0        NaN        NaN  \n1        NaN        NaN  \n2        NaN        NaN  \n3        NaN        NaN  \n4        NaN        NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>v1</th>\n      <th>v2</th>\n      <th>Unnamed: 2</th>\n      <th>Unnamed: 3</th>\n      <th>Unnamed: 4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"data = data.drop(labels = [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T20:58:48.242241Z","iopub.execute_input":"2025-11-22T20:58:48.242941Z","iopub.status.idle":"2025-11-22T20:58:48.253791Z","shell.execute_reply.started":"2025-11-22T20:58:48.242915Z","shell.execute_reply":"2025-11-22T20:58:48.252634Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"data.columns = [\"label\", \"txt\"]\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T20:58:52.149811Z","iopub.execute_input":"2025-11-22T20:58:52.150575Z","iopub.status.idle":"2025-11-22T20:58:52.159226Z","shell.execute_reply.started":"2025-11-22T20:58:52.150548Z","shell.execute_reply":"2025-11-22T20:58:52.158328Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"  label                                                txt\n0   ham  Go until jurong point, crazy.. Available only ...\n1   ham                      Ok lar... Joking wif u oni...\n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n3   ham  U dun say so early hor... U c already then say...\n4   ham  Nah I don't think he goes to usf, he lives aro...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>txt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T20:44:31.306870Z","iopub.execute_input":"2025-11-18T20:44:31.307176Z","iopub.status.idle":"2025-11-18T20:44:31.313790Z","shell.execute_reply.started":"2025-11-18T20:44:31.307149Z","shell.execute_reply":"2025-11-18T20:44:31.312711Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(5572, 2)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"data['label'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T20:44:32.456067Z","iopub.execute_input":"2025-11-18T20:44:32.456433Z","iopub.status.idle":"2025-11-18T20:44:32.470149Z","shell.execute_reply.started":"2025-11-18T20:44:32.456406Z","shell.execute_reply":"2025-11-18T20:44:32.469058Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"label\nham     4825\nspam     747\nName: count, dtype: int64"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"Remove Punctuatuions","metadata":{}},{"cell_type":"code","source":"import string\npunc = string.punctuation","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T20:44:33.276197Z","iopub.execute_input":"2025-11-18T20:44:33.276563Z","iopub.status.idle":"2025-11-18T20:44:33.281285Z","shell.execute_reply.started":"2025-11-18T20:44:33.276533Z","shell.execute_reply":"2025-11-18T20:44:33.280262Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":" def remove_punc(text):\n     return \"\".join([c for c in text if c not in punc])\n\ns = \"thi is text. * ?l\"\nprint(remove_punc(s))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T20:44:35.001264Z","iopub.execute_input":"2025-11-18T20:44:35.001640Z","iopub.status.idle":"2025-11-18T20:44:35.006814Z","shell.execute_reply.started":"2025-11-18T20:44:35.001616Z","shell.execute_reply":"2025-11-18T20:44:35.005828Z"}},"outputs":[{"name":"stdout","text":"thi is text  l\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"data[\"no punc\"] = data['txt'].apply(lambda x: remove_punc(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T20:44:36.025678Z","iopub.execute_input":"2025-11-18T20:44:36.026042Z","iopub.status.idle":"2025-11-18T20:44:36.068061Z","shell.execute_reply.started":"2025-11-18T20:44:36.026013Z","shell.execute_reply":"2025-11-18T20:44:36.066914Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T20:44:37.006328Z","iopub.execute_input":"2025-11-18T20:44:37.006703Z","iopub.status.idle":"2025-11-18T20:44:37.016717Z","shell.execute_reply.started":"2025-11-18T20:44:37.006672Z","shell.execute_reply":"2025-11-18T20:44:37.015481Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"  label                                                txt  \\\n0   ham  Go until jurong point, crazy.. Available only ...   \n1   ham                      Ok lar... Joking wif u oni...   \n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n3   ham  U dun say so early hor... U c already then say...   \n4   ham  Nah I don't think he goes to usf, he lives aro...   \n\n                                             no punc  \n0  Go until jurong point crazy Available only in ...  \n1                            Ok lar Joking wif u oni  \n2  Free entry in 2 a wkly comp to win FA Cup fina...  \n3        U dun say so early hor U c already then say  \n4  Nah I dont think he goes to usf he lives aroun...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>txt</th>\n      <th>no punc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>Go until jurong point crazy Available only in ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>Ok lar Joking wif u oni</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>U dun say so early hor U c already then say</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>Nah I dont think he goes to usf he lives aroun...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"**Tokenization**","metadata":{}},{"cell_type":"code","source":"import re\ndef tokenize(text):\n    return re.split(\"\\W+\", text)\n\ndata[\"tokenized\"] = data[\"no punc\"].apply(lambda x: tokenize(x.lower()))\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T20:44:39.666990Z","iopub.execute_input":"2025-11-18T20:44:39.667305Z","iopub.status.idle":"2025-11-18T20:44:39.799778Z","shell.execute_reply.started":"2025-11-18T20:44:39.667283Z","shell.execute_reply":"2025-11-18T20:44:39.798812Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"  label                                                txt  \\\n0   ham  Go until jurong point, crazy.. Available only ...   \n1   ham                      Ok lar... Joking wif u oni...   \n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n3   ham  U dun say so early hor... U c already then say...   \n4   ham  Nah I don't think he goes to usf, he lives aro...   \n\n                                             no punc  \\\n0  Go until jurong point crazy Available only in ...   \n1                            Ok lar Joking wif u oni   \n2  Free entry in 2 a wkly comp to win FA Cup fina...   \n3        U dun say so early hor U c already then say   \n4  Nah I dont think he goes to usf he lives aroun...   \n\n                                           tokenized  \n0  [go, until, jurong, point, crazy, available, o...  \n1                     [ok, lar, joking, wif, u, oni]  \n2  [free, entry, in, 2, a, wkly, comp, to, win, f...  \n3  [u, dun, say, so, early, hor, u, c, already, t...  \n4  [nah, i, dont, think, he, goes, to, usf, he, l...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>txt</th>\n      <th>no punc</th>\n      <th>tokenized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>Go until jurong point crazy Available only in ...</td>\n      <td>[go, until, jurong, point, crazy, available, o...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>Ok lar Joking wif u oni</td>\n      <td>[ok, lar, joking, wif, u, oni]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>U dun say so early hor U c already then say</td>\n      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>Nah I dont think he goes to usf he lives aroun...</td>\n      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"**Stopword Removal**","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import stopwords\nsw = stopwords.words('english')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T20:44:41.077136Z","iopub.execute_input":"2025-11-18T20:44:41.077481Z","iopub.status.idle":"2025-11-18T20:44:42.645160Z","shell.execute_reply.started":"2025-11-18T20:44:41.077457Z","shell.execute_reply":"2025-11-18T20:44:42.644410Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def remove_stopwords(text):\n    return [token for token in text if token not in sw]\n\n\ntokens = [\"I\", \"me\", \"stopwordds\", \"the\"]\nprint(remove_stopwords(tokens))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T20:44:44.587214Z","iopub.execute_input":"2025-11-18T20:44:44.588089Z","iopub.status.idle":"2025-11-18T20:44:44.594125Z","shell.execute_reply.started":"2025-11-18T20:44:44.588051Z","shell.execute_reply":"2025-11-18T20:44:44.592981Z"}},"outputs":[{"name":"stdout","text":"['I', 'stopwordds']\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"data[\"no_stop\"] = data[\"tokenized\"].apply(lambda x: remove_stopwords(x))\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T20:44:45.552002Z","iopub.execute_input":"2025-11-18T20:44:45.552876Z","iopub.status.idle":"2025-11-18T20:44:45.761084Z","shell.execute_reply.started":"2025-11-18T20:44:45.552846Z","shell.execute_reply":"2025-11-18T20:44:45.760290Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"  label                                                txt  \\\n0   ham  Go until jurong point, crazy.. Available only ...   \n1   ham                      Ok lar... Joking wif u oni...   \n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n3   ham  U dun say so early hor... U c already then say...   \n4   ham  Nah I don't think he goes to usf, he lives aro...   \n\n                                             no punc  \\\n0  Go until jurong point crazy Available only in ...   \n1                            Ok lar Joking wif u oni   \n2  Free entry in 2 a wkly comp to win FA Cup fina...   \n3        U dun say so early hor U c already then say   \n4  Nah I dont think he goes to usf he lives aroun...   \n\n                                           tokenized  \\\n0  [go, until, jurong, point, crazy, available, o...   \n1                     [ok, lar, joking, wif, u, oni]   \n2  [free, entry, in, 2, a, wkly, comp, to, win, f...   \n3  [u, dun, say, so, early, hor, u, c, already, t...   \n4  [nah, i, dont, think, he, goes, to, usf, he, l...   \n\n                                             no_stop  \n0  [go, jurong, point, crazy, available, bugis, n...  \n1                     [ok, lar, joking, wif, u, oni]  \n2  [free, entry, 2, wkly, comp, win, fa, cup, fin...  \n3      [u, dun, say, early, hor, u, c, already, say]  \n4  [nah, dont, think, goes, usf, lives, around, t...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>txt</th>\n      <th>no punc</th>\n      <th>tokenized</th>\n      <th>no_stop</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>Go until jurong point crazy Available only in ...</td>\n      <td>[go, until, jurong, point, crazy, available, o...</td>\n      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>Ok lar Joking wif u oni</td>\n      <td>[ok, lar, joking, wif, u, oni]</td>\n      <td>[ok, lar, joking, wif, u, oni]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>U dun say so early hor U c already then say</td>\n      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>Nah I dont think he goes to usf he lives aroun...</td>\n      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, y_train, X_test, y_test =train_test_split(X_features, data[\"labels\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T20:47:50.357024Z","iopub.execute_input":"2025-11-18T20:47:50.357398Z","iopub.status.idle":"2025-11-18T20:47:50.370656Z","shell.execute_reply.started":"2025-11-18T20:47:50.357327Z","shell.execute_reply":"2025-11-18T20:47:50.369414Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/879161839.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'X_features' is not defined"],"ename":"NameError","evalue":"name 'X_features' is not defined","output_type":"error"}],"execution_count":21},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T20:47:06.905930Z","iopub.execute_input":"2025-11-18T20:47:06.906267Z","iopub.status.idle":"2025-11-18T20:47:06.911211Z","shell.execute_reply.started":"2025-11-18T20:47:06.906244Z","shell.execute_reply":"2025-11-18T20:47:06.910150Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"Word to Vec","metadata":{}},{"cell_type":"code","source":"import gensim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T17:16:45.520815Z","iopub.execute_input":"2025-11-22T17:16:45.521057Z","iopub.status.idle":"2025-11-22T17:17:08.854245Z","shell.execute_reply.started":"2025-11-22T17:16:45.521035Z","shell.execute_reply":"2025-11-22T17:17:08.853021Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import gensim.downloader as api\napi.info().keys()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T17:24:20.574021Z","iopub.execute_input":"2025-11-22T17:24:20.574349Z","iopub.status.idle":"2025-11-22T17:24:20.623963Z","shell.execute_reply.started":"2025-11-22T17:24:20.574326Z","shell.execute_reply":"2025-11-22T17:24:20.623262Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"dict_keys(['corpora', 'models'])"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"\napi.info()['models'].keys()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T17:24:22.876495Z","iopub.execute_input":"2025-11-22T17:24:22.876799Z","iopub.status.idle":"2025-11-22T17:24:22.930127Z","shell.execute_reply.started":"2025-11-22T17:24:22.876777Z","shell.execute_reply":"2025-11-22T17:24:22.929211Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"dict_keys(['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis'])"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"wiki_embedding = api.load('glove-wiki-gigaword-100')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T17:33:03.225156Z","iopub.execute_input":"2025-11-22T17:33:03.225415Z","iopub.status.idle":"2025-11-22T17:33:51.194254Z","shell.execute_reply.started":"2025-11-22T17:33:03.225394Z","shell.execute_reply":"2025-11-22T17:33:51.193234Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"wiki_embedding.similar_by_word('hello')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T17:32:15.077312Z","iopub.execute_input":"2025-11-22T17:32:15.077644Z","iopub.status.idle":"2025-11-22T17:32:15.183289Z","shell.execute_reply.started":"2025-11-22T17:32:15.077610Z","shell.execute_reply":"2025-11-22T17:32:15.182426Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[('goodbye', 0.7905024290084839),\n ('hey', 0.7171452641487122),\n ('!', 0.6594691276550293),\n ('yeah', 0.6267022490501404),\n ('dear', 0.6220601201057434),\n ('mister', 0.6092501282691956),\n ('wow', 0.6079446077346802),\n ('muddah', 0.6048929691314697),\n ('mama', 0.6034210920333862),\n ('thank', 0.599325954914093)]"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"data['text_clean']= data['txt'].apply(lambda x: gensim.utils.simple_preprocess(x))\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T21:41:20.380635Z","iopub.execute_input":"2025-11-22T21:41:20.380947Z","iopub.status.idle":"2025-11-22T21:41:20.503624Z","shell.execute_reply.started":"2025-11-22T21:41:20.380921Z","shell.execute_reply":"2025-11-22T21:41:20.502918Z"}},"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"  label                                                txt  \\\n0   ham  Go until jurong point, crazy.. Available only ...   \n1   ham                      Ok lar... Joking wif u oni...   \n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n3   ham  U dun say so early hor... U c already then say...   \n4   ham  Nah I don't think he goes to usf, he lives aro...   \n\n                                          text_clean  \n0  [go, until, jurong, point, crazy, available, o...  \n1                        [ok, lar, joking, wif, oni]  \n2  [free, entry, in, wkly, comp, to, win, fa, cup...  \n3     [dun, say, so, early, hor, already, then, say]  \n4  [nah, don, think, he, goes, to, usf, he, lives...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>txt</th>\n      <th>text_clean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n      <td>[go, until, jurong, point, crazy, available, o...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n      <td>[ok, lar, joking, wif, oni]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>[free, entry, in, wkly, comp, to, win, fa, cup...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n      <td>[dun, say, so, early, hor, already, then, say]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>[nah, don, think, he, goes, to, usf, he, lives...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data['text_clean'], data['label'], test_size = 0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T17:38:59.918654Z","iopub.execute_input":"2025-11-22T17:38:59.919005Z","iopub.status.idle":"2025-11-22T17:39:00.109645Z","shell.execute_reply.started":"2025-11-22T17:38:59.918980Z","shell.execute_reply":"2025-11-22T17:39:00.108823Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"wv_model = gensim.models.Word2Vec(X_train, vector_size = 100, window = 5, min_count = 2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T17:44:14.736429Z","iopub.execute_input":"2025-11-22T17:44:14.737178Z","iopub.status.idle":"2025-11-22T17:44:15.115673Z","shell.execute_reply.started":"2025-11-22T17:44:14.737151Z","shell.execute_reply":"2025-11-22T17:44:15.114878Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"wv_model.wv.similar_by_word('hello')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T17:44:43.377325Z","iopub.execute_input":"2025-11-22T17:44:43.377689Z","iopub.status.idle":"2025-11-22T17:44:43.395543Z","shell.execute_reply.started":"2025-11-22T17:44:43.377655Z","shell.execute_reply":"2025-11-22T17:44:43.394741Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"[('my', 0.9994995594024658),\n ('he', 0.9994860291481018),\n ('them', 0.9994829297065735),\n ('they', 0.9994753003120422),\n ('already', 0.9994741082191467),\n ('im', 0.9994643926620483),\n ('the', 0.9994533061981201),\n ('well', 0.9994513988494873),\n ('off', 0.9994505643844604),\n ('ask', 0.9994495511054993)]"},"metadata":{}}],"execution_count":31},{"cell_type":"markdown","source":"**RNN**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nlabels = np.where(data['label']=='spam', 1, 0)\nX_train, X_test, y_train, y_test = train_test_split(data['txt'], labels, test_size =0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T20:59:06.514643Z","iopub.execute_input":"2025-11-22T20:59:06.515210Z","iopub.status.idle":"2025-11-22T20:59:07.200322Z","shell.execute_reply.started":"2025-11-22T20:59:06.515187Z","shell.execute_reply":"2025-11-22T20:59:07.199317Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"labels[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T19:28:01.285012Z","iopub.execute_input":"2025-11-22T19:28:01.285326Z","iopub.status.idle":"2025-11-22T19:28:01.291349Z","shell.execute_reply.started":"2025-11-22T19:28:01.285304Z","shell.execute_reply":"2025-11-22T19:28:01.290316Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"!pip install --upgrade pip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T21:11:50.691069Z","iopub.execute_input":"2025-11-22T21:11:50.691335Z","iopub.status.idle":"2025-11-22T21:11:57.001574Z","shell.execute_reply.started":"2025-11-22T21:11:50.691316Z","shell.execute_reply":"2025-11-22T21:11:57.000651Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\nCollecting pip\n  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\nDownloading pip-25.3-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\nSuccessfully installed pip-25.3\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"!pip install --upgrade tensorflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T21:12:05.123856Z","iopub.execute_input":"2025-11-22T21:12:05.124184Z","iopub.status.idle":"2025-11-22T21:13:07.508470Z","shell.execute_reply.started":"2025-11-22T21:12:05.124156Z","shell.execute_reply":"2025-11-22T21:13:07.503971Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\nCollecting tensorflow\n  Downloading tensorflow-2.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\nRequirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.5)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\nRequirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.15.0)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.74.0)\nCollecting tensorboard~=2.20.0 (from tensorflow)\n  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\nCollecting keras>=3.10.0 (from tensorflow)\n  Downloading keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\nCollecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n  Downloading ml_dtypes-0.5.4-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.8.2)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.10.0->tensorflow) (14.2.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.10.0->tensorflow) (0.1.0)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.10.0->tensorflow) (0.16.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.0->tensorflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.0->tensorflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.0->tensorflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.0->tensorflow) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.0->tensorflow) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.0->tensorflow) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.0->tensorflow) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.0->tensorflow) (2022.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.0->tensorflow) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\nDownloading tensorflow-2.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.6/620.6 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ml_dtypes-0.5.4-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n\u001b[?25hDownloading keras-3.12.0-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: ml_dtypes, tensorboard, keras, tensorflow\n\u001b[2K  Attempting uninstall: ml_dtypes\n\u001b[2K    Found existing installation: ml-dtypes 0.4.1\n\u001b[2K    Uninstalling ml-dtypes-0.4.1:\n\u001b[2K      Successfully uninstalled ml-dtypes-0.4.1\n\u001b[2K  Attempting uninstall: tensorboard━━━━━━━━━━━━━\u001b[0m \u001b[32m0/4\u001b[0m [ml_dtypes]\n\u001b[2K    Found existing installation: tensorboard 2.18.032m0/4\u001b[0m [ml_dtypes]\n\u001b[2K    Uninstalling tensorboard-2.18.0:━━━━━━━━\u001b[0m \u001b[32m0/4\u001b[0m [ml_dtypes]\n\u001b[2K      Successfully uninstalled tensorboard-2.18.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [tensorboard]\n\u001b[2K  Attempting uninstall: keras[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [tensorboard]\n\u001b[2K    Found existing installation: keras 3.8.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [tensorboard]\n\u001b[2K    Uninstalling keras-3.8.0:[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/4\u001b[0m [keras]d]\n\u001b[2K      Successfully uninstalled keras-3.8.0\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/4\u001b[0m [keras]\n\u001b[2K  Attempting uninstall: tensorflow90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/4\u001b[0m [keras]\n\u001b[2K    Found existing installation: tensorflow 2.18.0━━━━━━━━━━━━\u001b[0m \u001b[32m2/4\u001b[0m [keras]\n\u001b[2K    Uninstalling tensorflow-2.18.0:━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [tensorflow]\n\u001b[2K      Successfully uninstalled tensorflow-2.18.0\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [tensorflow]\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [tensorflow]4\u001b[0m [tensorflow]\n\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\ntf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.20.0 which is incompatible.\ntensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.20.0 which is incompatible.\ntensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.20.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-3.12.0 ml_dtypes-0.5.4 tensorboard-2.20.0 tensorflow-2.20.0\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T21:13:57.929183Z","iopub.execute_input":"2025-11-22T21:13:57.930025Z","iopub.status.idle":"2025-11-22T21:13:57.936417Z","shell.execute_reply.started":"2025-11-22T21:13:57.929975Z","shell.execute_reply":"2025-11-22T21:13:57.935553Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"\nX_train, X_test, y_train, y_test = train_test_split(data['txt'], labels, test_size = 0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T21:14:01.030719Z","iopub.execute_input":"2025-11-22T21:14:01.031568Z","iopub.status.idle":"2025-11-22T21:14:01.044531Z","shell.execute_reply.started":"2025-11-22T21:14:01.031543Z","shell.execute_reply":"2025-11-22T21:14:01.043837Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"max_words = 10000\ntokenizer = Tokenizer(num_words = max_words)\ntokenizer.fit_on_texts(X_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T21:14:03.431156Z","iopub.execute_input":"2025-11-22T21:14:03.431846Z","iopub.status.idle":"2025-11-22T21:14:03.530284Z","shell.execute_reply.started":"2025-11-22T21:14:03.431817Z","shell.execute_reply":"2025-11-22T21:14:03.529473Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"X_train_seq = tokenizer.texts_to_sequences(X_train)\nX_test_seq = tokenizer.texts_to_sequences(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T21:14:04.921453Z","iopub.execute_input":"2025-11-22T21:14:04.922156Z","iopub.status.idle":"2025-11-22T21:14:05.002613Z","shell.execute_reply.started":"2025-11-22T21:14:04.922129Z","shell.execute_reply":"2025-11-22T21:14:05.001779Z"}},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":"برای این که بتونیم دنباله هارو توی مدل استفاده کنیم نیاز به استفاده از بچ هست\nبرای استفاده از بچ باید طول رشته ها برابر باشه \nپدینگی که پایین استفاده می کنیم طول همه رشته ها رو برابر با طول طولانی ترین رشته می کنه و باقی رو صفر می ذاره","metadata":{}},{"cell_type":"code","source":"X_train_seq_padded = pad_sequences(X_train_seq)\nX_test_seq_padded = pad_sequences(X_test_seq)\nX_train_seq_padded[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T21:14:07.950589Z","iopub.execute_input":"2025-11-22T21:14:07.951286Z","iopub.status.idle":"2025-11-22T21:14:07.979350Z","shell.execute_reply.started":"2025-11-22T21:14:07.951258Z","shell.execute_reply":"2025-11-22T21:14:07.978595Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   1,  67, 413,  47,  81], dtype=int32)"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"from tensorflow.keras.metrics import Precision, Recall\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n\nmodel = Sequential()\nmodel.add(Embedding(input_dim = max_words, output_dim = 50))\nmodel.add(LSTM(32, dropout = 0, recurrent_dropout =0))\nmodel.add(Dense(32, activation = 'relu'))\nmodel.add(Dense(1, activation = 'sigmoid'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T21:14:09.830295Z","iopub.execute_input":"2025-11-22T21:14:09.830993Z","iopub.status.idle":"2025-11-22T21:14:09.858581Z","shell.execute_reply.started":"2025-11-22T21:14:09.830966Z","shell.execute_reply":"2025-11-22T21:14:09.857674Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"model.compile(optimizer = 'adam',\n             loss = 'binary_crossentropy',\n             metrics = ['accuracy', Precision(), Recall()])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T21:14:12.360330Z","iopub.execute_input":"2025-11-22T21:14:12.361269Z","iopub.status.idle":"2025-11-22T21:14:12.382040Z","shell.execute_reply.started":"2025-11-22T21:14:12.361238Z","shell.execute_reply":"2025-11-22T21:14:12.381104Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"history = model.fit(X_train_seq_padded, y_train, \n                   batch_size = 32, epochs = 10,\n                   validation_data = (X_test_seq_padded, y_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T21:14:14.430372Z","iopub.execute_input":"2025-11-22T21:14:14.430727Z","iopub.status.idle":"2025-11-22T21:15:49.315992Z","shell.execute_reply.started":"2025-11-22T21:14:14.430703Z","shell.execute_reply":"2025-11-22T21:15:49.315222Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 68ms/step - accuracy: 0.8617 - loss: 0.3887 - precision_3: 0.5515 - recall_3: 0.2247 - val_accuracy: 0.9830 - val_loss: 0.0538 - val_precision_3: 0.9833 - val_recall_3: 0.8741\nEpoch 2/10\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.9911 - loss: 0.0374 - precision_3: 0.9875 - recall_3: 0.9468 - val_accuracy: 0.9910 - val_loss: 0.0299 - val_precision_3: 0.9630 - val_recall_3: 0.9630\nEpoch 3/10\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.9978 - loss: 0.0109 - precision_3: 0.9990 - recall_3: 0.9852 - val_accuracy: 0.9901 - val_loss: 0.0359 - val_precision_3: 0.9921 - val_recall_3: 0.9259\nEpoch 4/10\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.9995 - loss: 0.0027 - precision_3: 0.9984 - recall_3: 0.9980 - val_accuracy: 0.9937 - val_loss: 0.0253 - val_precision_3: 0.9848 - val_recall_3: 0.9630\nEpoch 5/10\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.9996 - loss: 0.0028 - precision_3: 1.0000 - recall_3: 0.9972 - val_accuracy: 0.9928 - val_loss: 0.0283 - val_precision_3: 0.9922 - val_recall_3: 0.9481\nEpoch 6/10\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - accuracy: 0.9992 - loss: 0.0038 - precision_3: 1.0000 - recall_3: 0.9947 - val_accuracy: 0.9901 - val_loss: 0.0321 - val_precision_3: 0.9921 - val_recall_3: 0.9259\nEpoch 7/10\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 1.9919e-04 - precision_3: 1.0000 - recall_3: 1.0000 - val_accuracy: 0.9964 - val_loss: 0.0242 - val_precision_3: 0.9925 - val_recall_3: 0.9778\nEpoch 8/10\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.9992 - loss: 0.0011 - precision_3: 0.9939 - recall_3: 1.0000 - val_accuracy: 0.9928 - val_loss: 0.0333 - val_precision_3: 1.0000 - val_recall_3: 0.9407\nEpoch 9/10\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 1.0937e-04 - precision_3: 1.0000 - recall_3: 1.0000 - val_accuracy: 0.9928 - val_loss: 0.0310 - val_precision_3: 0.9922 - val_recall_3: 0.9481\nEpoch 10/10\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 6.6148e-05 - precision_3: 1.0000 - recall_3: 1.0000 - val_accuracy: 0.9919 - val_loss: 0.0322 - val_precision_3: 0.9922 - val_recall_3: 0.9407\n","output_type":"stream"}],"execution_count":36},{"cell_type":"markdown","source":"# **RNN Word2Vec**# ","metadata":{}},{"cell_type":"code","source":"import gensim\n\ntokenizer =  Tokenizer(num_words = max_words)\nclean_X_train = X_train.apply(lambda x: gensim.utils.simple_preprocess(x))\nwv_model = gensim.models.Word2Vec(clean_X_train, vector_size = 100, window = 5, min_count = 2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T21:41:48.708013Z","iopub.execute_input":"2025-11-22T21:41:48.708577Z","iopub.status.idle":"2025-11-22T21:41:49.137020Z","shell.execute_reply.started":"2025-11-22T21:41:48.708552Z","shell.execute_reply":"2025-11-22T21:41:49.136067Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"max_words = 10000\ntokenizer = Tokenizer(num_words = max_words)\ntokenizer.fit_on_texts(X_train)\nembedding_size = 100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T21:43:05.818487Z","iopub.execute_input":"2025-11-22T21:43:05.819180Z","iopub.status.idle":"2025-11-22T21:43:05.910103Z","shell.execute_reply.started":"2025-11-22T21:43:05.819153Z","shell.execute_reply":"2025-11-22T21:43:05.909124Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"embedding_matrix = np.zeros((max_words, embedding_size))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T21:43:06.888962Z","iopub.execute_input":"2025-11-22T21:43:06.889252Z","iopub.status.idle":"2025-11-22T21:43:06.893730Z","shell.execute_reply.started":"2025-11-22T21:43:06.889230Z","shell.execute_reply":"2025-11-22T21:43:06.892892Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"\nfor word, index in tokenizer.word_index.items():\n    if index < max_words:\n        if word in wv_model.wv:\n            embedding_matrix[index] = wv_model.wv[word]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T21:44:52.507063Z","iopub.execute_input":"2025-11-22T21:44:52.507342Z","iopub.status.idle":"2025-11-22T21:44:52.528347Z","shell.execute_reply.started":"2025-11-22T21:44:52.507323Z","shell.execute_reply":"2025-11-22T21:44:52.527584Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"from tensorflow.keras.metrics import Precision, Recall\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n\nmodel = Sequential()\nmodel.add(Embedding(input_dim = max_words, output_dim = embedding_size,\n                    weights =[embedding_matrix],\n                   trainable = False))\nmodel.add(LSTM(32, dropout = 0, recurrent_dropout =0))\nmodel.add(Dense(32, activation = 'relu'))\nmodel.add(Dense(1, activation = 'sigmoid'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T21:47:40.389128Z","iopub.execute_input":"2025-11-22T21:47:40.389990Z","iopub.status.idle":"2025-11-22T21:47:40.422266Z","shell.execute_reply.started":"2025-11-22T21:47:40.389962Z","shell.execute_reply":"2025-11-22T21:47:40.421336Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"model.compile(optimizer = 'adam',\n              loss = 'binary_crossentropy',\n              metrics = ['accuracy', Precision(), Recall()]\n             )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T21:47:50.157899Z","iopub.execute_input":"2025-11-22T21:47:50.158811Z","iopub.status.idle":"2025-11-22T21:47:50.176982Z","shell.execute_reply.started":"2025-11-22T21:47:50.158737Z","shell.execute_reply":"2025-11-22T21:47:50.176024Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"history = model.fit(X_train_seq_padded, y_train, \n                   batch_size = 32, epochs = 10,\n                   validation_data = (X_test_seq_padded, y_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T21:48:04.735155Z","iopub.execute_input":"2025-11-22T21:48:04.736043Z","iopub.status.idle":"2025-11-22T21:49:34.847669Z","shell.execute_reply.started":"2025-11-22T21:48:04.736013Z","shell.execute_reply":"2025-11-22T21:49:34.846754Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 66ms/step - accuracy: 0.8604 - loss: 0.4291 - precision_4: 0.4077 - recall_4: 0.0625 - val_accuracy: 0.8942 - val_loss: 0.2686 - val_precision_4: 0.6889 - val_recall_4: 0.2296\nEpoch 2/10\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 63ms/step - accuracy: 0.8862 - loss: 0.2758 - precision_4: 0.7009 - recall_4: 0.3075 - val_accuracy: 0.8960 - val_loss: 0.2599 - val_precision_4: 0.7568 - val_recall_4: 0.2074\nEpoch 3/10\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 62ms/step - accuracy: 0.8873 - loss: 0.2721 - precision_4: 0.6943 - recall_4: 0.4154 - val_accuracy: 0.8996 - val_loss: 0.2591 - val_precision_4: 0.6667 - val_recall_4: 0.3407\nEpoch 4/10\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 61ms/step - accuracy: 0.8870 - loss: 0.2631 - precision_4: 0.6991 - recall_4: 0.3919 - val_accuracy: 0.9031 - val_loss: 0.2291 - val_precision_4: 0.7077 - val_recall_4: 0.3407\nEpoch 5/10\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 61ms/step - accuracy: 0.9018 - loss: 0.2320 - precision_4: 0.6875 - recall_4: 0.4506 - val_accuracy: 0.9175 - val_loss: 0.2184 - val_precision_4: 0.8209 - val_recall_4: 0.4074\nEpoch 6/10\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 61ms/step - accuracy: 0.9088 - loss: 0.2235 - precision_4: 0.7493 - recall_4: 0.5274 - val_accuracy: 0.9067 - val_loss: 0.2508 - val_precision_4: 0.9189 - val_recall_4: 0.2519\nEpoch 7/10\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 61ms/step - accuracy: 0.9161 - loss: 0.2205 - precision_4: 0.7811 - recall_4: 0.5369 - val_accuracy: 0.9148 - val_loss: 0.2202 - val_precision_4: 0.8448 - val_recall_4: 0.3630\nEpoch 8/10\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 62ms/step - accuracy: 0.9233 - loss: 0.1906 - precision_4: 0.8010 - recall_4: 0.5922 - val_accuracy: 0.9256 - val_loss: 0.2114 - val_precision_4: 0.6548 - val_recall_4: 0.8148\nEpoch 9/10\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 61ms/step - accuracy: 0.9293 - loss: 0.1884 - precision_4: 0.7825 - recall_4: 0.6327 - val_accuracy: 0.9265 - val_loss: 0.1959 - val_precision_4: 0.9206 - val_recall_4: 0.4296\nEpoch 10/10\n\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 62ms/step - accuracy: 0.9300 - loss: 0.1931 - precision_4: 0.8279 - recall_4: 0.6164 - val_accuracy: 0.9632 - val_loss: 0.1404 - val_precision_4: 0.8615 - val_recall_4: 0.8296\n","output_type":"stream"}],"execution_count":69},{"cell_type":"code","source":"import gensim.downloader as api\nwv_model = api.load('glove-wiki-gigaword-100')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T21:55:44.379667Z","iopub.execute_input":"2025-11-22T21:55:44.380681Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"embedding_size = 100\nembedding_matrix = np.zeros((max_words, embedding_size))\nfor word, index in tokenizer.word_index.items():\n    if index < max_words:\n        if word in wv_model.wv:\n            embedding_matrix[index] = wv_model[word]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T21:54:54.108516Z","iopub.execute_input":"2025-11-22T21:54:54.109366Z","iopub.status.idle":"2025-11-22T21:54:54.138857Z","shell.execute_reply.started":"2025-11-22T21:54:54.109338Z","shell.execute_reply":"2025-11-22T21:54:54.137780Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/3398938988.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0membedding_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwv_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: 'Word2Vec' object is not subscriptable"],"ename":"TypeError","evalue":"'Word2Vec' object is not subscriptable","output_type":"error"}],"execution_count":72},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}